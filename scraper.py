"""
Madam Coco √úr√ºn √áekme Scripti
Selenium ile t√ºm √ºr√ºnleri √ßeker ve CSV'ye kaydeder
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
from datetime import datetime

class MadamCocoScraper:
    def __init__(self):
        """Selenium ba≈ülat"""
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        options.binary_location = '/usr/bin/chromium-browser'  # Ubuntu'da Chromium
    
    from selenium.webdriver.chrome.service import Service
    service = Service('/usr/bin/chromedriver')
    
    self.driver = webdriver.Chrome(service=service, options=options)
        
        self.driver = webdriver.Chrome(options=options)
        self.products = []
    
    def scrape_category(self, category_url, max_pages=5):
        """Kategoriden √ºr√ºnleri √ßek"""
        print(f"\nüîç Kategori taranƒ±yor: {category_url}")
        
        for page in range(1, max_pages + 1):
            url = f"{category_url}?page={page}"
            print(f"\nüìÑ Sayfa {page} √ßekiliyor...")
            
            try:
                self.driver.get(url)
                time.sleep(3)  # Sayfa y√ºklensin
                
                # Scroll down - lazy loading i√ßin
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # √úr√ºn kartlarƒ±nƒ± bul
                products_found = self.extract_products()
                
                if not products_found:
                    print(f"‚ö†Ô∏è Sayfa {page}'de √ºr√ºn bulunamadƒ±, durduruluyor")
                    break
                
                print(f"‚úÖ {len(products_found)} √ºr√ºn √ßekildi")
                
            except Exception as e:
                print(f"‚ùå Sayfa {page} hatasƒ±: {e}")
                break
        
        print(f"\nüéâ Toplam {len(self.products)} √ºr√ºn √ßekildi!")
    
    def extract_products(self):
        """Sayfadaki √ºr√ºnleri √ßƒ±kar"""
        found = []
        
        # Farklƒ± CSS selector'larƒ± dene
        selectors = [
            "div.product-item",
            "div.product-card", 
            "article.product",
            "div[data-product-id]",
            ".product",
        ]
        
        for selector in selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"üì¶ {len(elements)} √ºr√ºn bulundu ({selector})")
                    
                    for element in elements:
                        product = self.parse_product(element)
                        if product:
                            self.products.append(product)
                            found.append(product)
                    
                    return found
            except:
                continue
        
        return found
    
    def parse_product(self, element):
        """Tek √ºr√ºn√º parse et"""
        try:
            # √úr√ºn adƒ±
            name = None
            name_selectors = ["h3", "h2", ".product-name", ".product-title", "a"]
            for sel in name_selectors:
                try:
                    name = element.find_element(By.CSS_SELECTOR, sel).text.strip()
                    if name:
                        break
                except:
                    continue
            
            # Fiyat
            price = None
            price_selectors = [".price", ".product-price", "span.price-value"]
            for sel in price_selectors:
                try:
                    price_text = element.find_element(By.CSS_SELECTOR, sel).text
                    price = self.parse_price(price_text)
                    if price:
                        break
                except:
                    continue
            
            # Link
            link = None
            try:
                link = element.find_element(By.TAG_NAME, "a").get_attribute("href")
            except:
                pass
            
            # G√∂rsel
            image = None
            try:
                img = element.find_element(By.TAG_NAME, "img")
                image = img.get_attribute("src") or img.get_attribute("data-src")
            except:
                pass
            
            if name and price:
                return {
                    '√úr√ºn Adƒ±': name,
                    'Fiyat': price,
                    'Link': link,
                    'G√∂rsel': image,
                    'Tarih': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
        
        except Exception as e:
            pass
        
        return None
    
    def parse_price(self, price_text):
        """Fiyatƒ± sayƒ±ya √ßevir"""
        import re
        if not price_text:
            return None
        
        # Sadece rakam ve virg√ºl/nokta
        clean = re.sub(r'[^\d,.]', '', price_text)
        clean = clean.replace('.', '').replace(',', '.')
        
        try:
            return float(clean)
        except:
            return None
    
    def save_to_csv(self, filename='output/madamcoco_products.csv'):
        """CSV'ye kaydet"""
        if not self.products:
            print("‚ö†Ô∏è Kaydedilecek √ºr√ºn yok!")
            return
        
        df = pd.DataFrame(self.products)
        
        # Klas√∂r yoksa olu≈ütur
        import os
        os.makedirs('output', exist_ok=True)
        
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\nüíæ {len(self.products)} √ºr√ºn kaydedildi: {filename}")
        
        # √ñnizleme
        print(f"\nüìä ƒ∞lk 5 √ºr√ºn:")
        print(df.head())
    
    def close(self):
        """Tarayƒ±cƒ±yƒ± kapat"""
        self.driver.quit()


# KULLANIM
if __name__ == "__main__":
    print("üõçÔ∏è MADAM COCO SCRAPER")
    print("=" * 50)
    
    scraper = MadamCocoScraper()
    
    # Kategoriler
    categories = [
        "https://www.madamcoco.com.tr/ev-tekstili",
        # Buraya daha fazla kategori ekleyebilirsiniz
    ]
    
    for category in categories:
        scraper.scrape_category(category, max_pages=3)
    
    # CSV'ye kaydet
    scraper.save_to_csv()
    
    scraper.close()
    
    print("\n‚úÖ ƒ∞≈ülem tamamlandƒ±!")
